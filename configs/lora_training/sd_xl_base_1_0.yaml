model:
  target: sgm.models.diffusion.LoraDiffusionEngine
  params:
    scale_factor: 0.13025
    disable_first_stage_autocast: True
    placeholder_tokens: ["<s1>", "<s2>"]
    initializer_tokens: ["<rand-0.017>", "<rand-0.017>"]
    unet_lora_lr: 1e-4
    te_lora_lr: 1e-5
    te_ti_lr: 5e-4
    te_ti_continue_lr: 1e-4
    # ckpt_path: "/app/ckpaths/sd_xl_base_1.0.safetensors"
    log_keys:
      - cls

    optimizer_config:
      target: torch.optim.AdamW
      params:
        betas: [0.9, 0.999]
        eps: 1.0e-8
        weight_decay: 0.0

    scheduler_config:
      target: sgm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [0]
        cycle_lengths: [1000]
        f_start: [1]
        f_max: [1.]
        f_min: [0.01]

    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
      params:
        num_idx: 1000
        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    network_config:
      target: sgm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        adm_in_channels: 2816
        num_classes: sequential
        use_checkpoint: False
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2]
        num_res_blocks: 2
        channel_mult: [1, 2, 4]
        num_head_channels: 64
        use_linear_in_transformer: True
        transformer_depth: [1, 2, 10]
        context_dim: 2048
        spatial_transformer_attn_type: softmax-xformers

    conditioner_config:
      target: sgm.modules.GeneralConditioner
      params:
        emb_models:
          - is_trainable: True
            input_key: txt
            target: sgm.modules.encoders.modules.FrozenCLIPEmbedder
            params:
              layer: hidden
              layer_idx: 11
              freeze: False

          - is_trainable: True
            input_key: txt
            target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder2
            params:
              arch: ViT-bigG-14
              version: laion2b_s39b_b160k
              freeze: False
              layer: penultimate
              always_return_pooled: True
              legacy: False

          - is_trainable: False
            input_key: original_size_as_tuple
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256

          - is_trainable: False
            input_key: crop_coords_top_left
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256

          - is_trainable: False
            input_key: target_size_as_tuple
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256

    first_stage_config:
      target: sgm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          attn_type: vanilla-xformers
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    loss_fn_config:
      target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss
      params:        
        loss_weighting_config:
          target: sgm.modules.diffusionmodules.loss_weighting.EpsWeighting
        sigma_sampler_config:
          target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
          params:
            num_idx: 1000
            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    sampler_config:
      target: sgm.modules.diffusionmodules.sampling.EulerEDMSampler
      params:
        num_steps: 50

        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

        guider_config:
          target: sgm.modules.diffusionmodules.guiders.VanillaCFG
          params:
            scale: 5.0

data:
  target: sgm.data.dataset.StableDataModuleFromConfig
  params:
    skip_val_loader: True
    train:
      datapipeline:
        urls:
          - "/app/.data/"
        pipeline_config:
          shardshuffle: 10000
          sample_shuffle: 1
          split_data_by_worker: True
          repeat: 1

        decoders:
          - "pil"

        postprocessors:
          - target: sdata.mappers.TorchVisionImageTransforms
            params:
              key: 'jpg' # USER: you might wanna adapt this for your custom dataset
              transforms:
                - target: torchvision.transforms.Resize
                  params:
                    size: 1024
                    interpolation: 3
                # - target: torchvision.transforms.ColorJitter
                #   params:
                #     brightness: 0.2
                #     contrast: 0.2
                #     saturation: 0.2
                #     hue: 0.1
                - target: torchvision.transforms.ToTensor
          - target: sdata.mappers.Rescaler
          - target: sdata.mappers.AddOriginalImageSizeAsTupleAndCropToSquare
            params:
              use_data_key: True
              h_key: height # USER: you might wanna adapt this for your custom dataset
              w_key: width # USER: you might wanna adapt this for your custom dataset
          - target: sdata.mappers.AddTargetSizeAsTuple
            params:
              target_height: 1024 # USER: you might wanna adapt this for your custom dataset
              target_width: 1024 # USER: you might wanna adapt this for your custom dataset

      loader:
        batch_size: 1
        num_workers: 2

lightning:
  callbacks:
    image_logger:
      target: lora_main.ImageLogger
      params:
        disabled: False
        enable_autocast: False
        batch_frequency: 1000
        max_images: 8
        increase_log_steps: True
        log_first_step: False
        log_images_kwargs:
          use_ema_scope: False
          N: 8
          n_rows: 2

  trainer:
    devices: 0,
    benchmark: True
    num_sanity_val_steps: 0
    accumulate_grad_batches: 5
    max_epochs: 500
    reload_dataloaders_every_n_epochs: 0
    strategy: "ddp"
    gradient_clip_val: 1.0

